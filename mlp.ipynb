{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a314a5",
   "metadata": {},
   "source": [
    "**Multilayer Perceptron(MLP)** \n",
    "\n",
    "Referring research paper - [A Neural Probabilistic Language Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490e51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a1fbae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"names.txt\").read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa1a98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acee28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f06262",
   "metadata": {},
   "source": [
    "The NN in research paper\n",
    "\n",
    "![alt text](img/mlp_NN.png)\n",
    "\n",
    "We will create our NN similar to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55b2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the dataset and dataloader\n",
    "block_size = 3\n",
    "x, y = [], []\n",
    "for w in words:\n",
    "    # print(w)\n",
    "    context = [0]*block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        x.append(context)\n",
    "        y.append(ix)\n",
    "        # print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "        context = context[1:] + [ix]  # crop and append\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efa7d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2274923e",
   "metadata": {},
   "source": [
    "C is our Embedding mapping that will map character index to the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20822533",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.randn((27,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96340ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = c[x]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2be974",
   "metadata": {},
   "source": [
    "Now, first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44182a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn((6,100)) # 2*3 , 100 neurons\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0cb21f",
   "metadata": {},
   "source": [
    "We want \n",
    ">emb @ w\n",
    "\n",
    "but their shapes are not compatible  ([16, 3, 2]) and ([6, 100]).\n",
    "\n",
    "Therefore we will **concatenate** them along **dimension 1** i.e. \n",
    "\n",
    "**[no.of samples, no. of neurons in inp, vector embedding]** --> along **no. of neurons in inp to get ([16, 6]).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a730bcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([emb[:,0,:], emb[:,1,:], emb[:,2,:]], dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904baa4c",
   "metadata": {},
   "source": [
    "But only doing concatenate won't work, what if we change the context size from 3 to more. So, to overcome this we can use \n",
    "\n",
    ">**torch.unbind(emb, dim=1)**\n",
    "\n",
    "which removes thedimension from the tensor and then we can concatenate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f9724c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, dim=1), dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c0f6f",
   "metadata": {},
   "source": [
    "To make this even more easy, we can basically use \n",
    "\n",
    ">**emb.view(16,6)**\n",
    "\n",
    "and this will work easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105f5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.tanh(emb.view(emb.shape[0], 6) @ w1 + b1) # emb.shape[0], 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6892d173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a5443",
   "metadata": {},
   "source": [
    "Now, 2nd hidden layer (Here the output layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b592fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = torch.randn((100,27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6eb225b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ w2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ec5be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "815f14b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = counts/counts.sum(dim=-1, keepdim = True)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6189c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -probs[torch.arange(x.shape[0]),y].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22acd9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.2408)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6044cb92",
   "metadata": {},
   "source": [
    "**Finally**\n",
    "\n",
    "Now we will do this all continuously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42e559ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape #Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c39c1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "c = torch.randn((27,2), generator=g)\n",
    "w1 = torch.randn((6,100), generator=g) # 2*3 , 100 neurons\n",
    "b1 = torch.randn(100, generator=g)  \n",
    "w2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [c, w1, b1, w2, b2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06e14fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57892878",
   "metadata": {},
   "source": [
    "We can replace this \n",
    "\n",
    ">counts = logits.exp()\n",
    "\n",
    ">probs = counts/counts.sum(dim=-1, keepdim = True)\n",
    "\n",
    ">loss = -probs[torch.arange(16),y].log().mean()\n",
    "\n",
    "with\n",
    "\n",
    ">F.cross_entropy(logits, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "807ba0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "851fb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000) # log learning rates\n",
    "lrs = 10**lre # learning rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d89e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1009087562561035\n"
     ]
    }
   ],
   "source": [
    "lri = []\n",
    "lossesi = []\n",
    "\n",
    "#forward pass\n",
    "for epoch in range(10000):\n",
    "    #mini-batch\n",
    "    ix = torch.randint(0, x.shape[0], (32,))\n",
    "\n",
    "    emb = c[x[ix]] # 32, 3, 2\n",
    "    h = torch.tanh(emb.view(emb.shape[0], 6) @ w1 + b1) # emb.shape[0], 6\n",
    "    logits = h @ w2 + b2\n",
    "    loss = F.cross_entropy(logits, y[ix])\n",
    "    \n",
    "\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    #update\n",
    "    # lr = lrs[epoch]\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    # lri.append(lre[epoch])\n",
    "    # lossesi.append(loss.item())\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec52a2",
   "metadata": {},
   "source": [
    "As we can see it takes a lot of time to forward and backard these 220000.... something values, so we have used **mini-batches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d5c653",
   "metadata": {},
   "source": [
    "![alt text](img/lrcurve.png)\n",
    "\n",
    "We got to know that the learning rate 0.1 is somewhat best for us so we will use that only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6f6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
